<!doctype html><html lang="es"><head>
<meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1">
<title>P2 — en movimiento </title>
<link rel="stylesheet" href="style.css">
<script defer src="state.js"></script>
<style>#cam.mirror{transform:scaleX(-1);}</style>
</head><body>
<main class="wrap">
  <div class="card">
    <h1>2) en movimiento </h1>

    <div class="grid2">
      <div>
        <video id="cam" playsinline autoplay muted style="width:100%;border-radius:12px;background:#000"></video>
        <div class="actions" style="margin-top:10px;gap:8px;flex-wrap:wrap">
          <button class="btn" id="toggleFacing">↔︎ Cambiar cámara</button>
          <button class="btn" id="rec">● Grabar</button>
          <button class="btn" id="stop" disabled>■ Detener</button>
        </div>
        <p class="hint" id="hint">Pulsa “Grabar”, luego “Detener” o espera el autostop a los 5 s.</p>
      </div>

      <div>
        <label>Previsualización</label>
        <div class="preview" id="prev">Aún sin vídeo</div>
      </div>
    </div>

    <div class="actions">
      <a class="btn" href="q1.html">← Volver</a>
      <button class="btn primary" id="next" disabled>Siguiente →</button>
    </div>
  </div>
</main>

<script>
const videoEl   = document.getElementById('cam');
const btnFacing = document.getElementById('toggleFacing');
const btnRec    = document.getElementById('rec');
const btnStop   = document.getElementById('stop');
const btnNext   = document.getElementById('next');
const prev      = document.getElementById('prev');
const hint      = document.getElementById('hint');

let facingMode = 'user';   // 'user' (frontal) | 'environment' (trasera)
let camStream  = null;
let recorder   = null;
let chunks     = [];
let rafId      = null;
let videoDataUrl = null;

async function startCamera(){
  try{
    stopAll();
    camStream = await navigator.mediaDevices.getUserMedia({
      video: { facingMode:{ ideal:facingMode }, width:{ideal:1280}, height:{ideal:720} },
      audio: true
    });
    videoEl.srcObject = camStream;
    // espejo solo en frontal (vista previa)
    videoEl.classList.toggle('mirror', facingMode==='user');
  }catch(e){
    alert('No se pudo acceder a la cámara.');
    console.error(e);
  }
}
startCamera();

btnFacing.addEventListener('click', async ()=>{
  facingMode = (facingMode==='user') ? 'environment' : 'user';
  await startCamera();
});

// pipeline espejo con canvas para que EL ARCHIVO final también quede en espejo en frontal
function buildMirroredStream(sourceVideo, sourceStream){
  const vw = sourceVideo.videoWidth  || 640;
  const vh = sourceVideo.videoHeight || 360;
  const canvas = document.createElement('canvas');
  canvas.width = vw; canvas.height = vh;
  const ctx = canvas.getContext('2d');

  function draw(){
    ctx.save();
    ctx.translate(canvas.width, 0);
    ctx.scale(-1, 1);
    ctx.drawImage(sourceVideo, 0, 0, canvas.width, canvas.height);
    ctx.restore();
    rafId = requestAnimationFrame(draw);
  }
  draw();

  const stream = canvas.captureStream(30);
  const audioTrack = sourceStream.getAudioTracks()[0];
  if (audioTrack) stream.addTrack(audioTrack);
  const stopFn = ()=>{ if(rafId) cancelAnimationFrame(rafId); };
  return { stream, stopFn };
}

btnRec.addEventListener('click', async ()=>{
  if(!camStream){ alert('No hay cámara'); return; }
  chunks = [];
  btnRec.disabled = true; btnStop.disabled = true;

  // espera un frame para que videoWidth esté listo
  if (!videoEl.videoWidth) await new Promise(r=>setTimeout(r,200));

  let streamToRecord = camStream;
  let stopMirror = null;
  if (facingMode==='user'){ // frontal → graba espejado
    const built = buildMirroredStream(videoEl, camStream);
    streamToRecord = built.stream;
    stopMirror = built.stopFn;
  }

  try{
    recorder = new MediaRecorder(streamToRecord, { mimeType:'video/webm' });
  }catch(e){
    // fallback sin mimeType por compatibilidad
    recorder = new MediaRecorder(streamToRecord);
  }

  recorder.ondataavailable = e=> chunks.push(e.data);
  recorder.onstop = async ()=>{
    if (stopMirror) stopMirror();
    const blob = new Blob(chunks, { type:'video/webm' });
    videoDataUrl = await blobToDataURL(blob);

    const v = document.createElement('video');
    v.controls = true; v.src = videoDataUrl;
    v.style.width='100%'; v.style.borderRadius='12px';
    prev.innerHTML = ''; prev.appendChild(v);

    // ✅ habilitar “Siguiente” sí o sí
    btnNext.disabled = false;
    btnNext.removeAttribute('disabled');
  };

  recorder.start();
  hint.textContent = 'Grabando…';
  btnStop.disabled = false;

  // autostop a los 5s
  setTimeout(()=>{
    if (recorder && recorder.state==='recording'){ recorder.stop(); hint.textContent='Grabación finalizada'; }
    btnRec.disabled = false; btnStop.disabled = true;
  }, 5000);
});

btnStop.addEventListener('click', ()=>{
  if (recorder && recorder.state==='recording'){
    recorder.stop(); hint.textContent='Grabación finalizada';
  }
  btnRec.disabled = false; btnStop.disabled = true;
});

btnNext.addEventListener('click', ()=>{
  // guarda en estado temporal (aunque no exista writeTmp)
  try{
    if (typeof writeTmp==='function') {
      writeTmp({ videoClip: videoDataUrl || null });
    } else {
      sessionStorage.setItem('videoClip', videoDataUrl || '');
    }
  }catch(e){ console.warn('No se pudo usar writeTmp, uso sessionStorage'); }

  stopAll();
  // ✅ navega a la tercera página
  location.href = 'q3.html';
});

function stopAll(){
  if (recorder && recorder.state==='recording'){ recorder.stop(); }
  if (camStream){ camStream.getTracks().forEach(t=>t.stop()); camStream=null; }
  if (rafId){ cancelAnimationFrame(rafId); rafId=null; }
}

window.addEventListener('pagehide', stopAll);

function blobToDataURL(blob){
  return new Promise(res=>{ const r=new FileReader(); r.onload=()=>res(r.result); r.readAsDataURL(blob); });
}
</script>
</body></html>
